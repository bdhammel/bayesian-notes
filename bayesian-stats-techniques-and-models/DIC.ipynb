{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deviance information criterion (DIC)\n",
    "\n",
    "There is no DIC function in Pyro so we need to write our own\n",
    "https://www.rdocumentation.org/packages/SpatialExtremes/versions/2.0-7.2/topics/DIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax import random\n",
    "import jax.numpy as np\n",
    "import numpy as onp\n",
    "\n",
    "import numpyro\n",
    "import numpyro.distributions as dist\n",
    "from numpyro.infer import MCMC, NUTS\n",
    "\n",
    "num_warmup, num_samples = 1000, 5000\n",
    "rng_key = random.PRNGKey(0)\n",
    "rng_key, rng_key_ = random.split(rng_key)\n",
    "numpyro.set_host_device_count(3)\n",
    "numpyro.enable_validation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define two models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(-1, 1)\n",
    "t = 2.5 * x + onp.random.normal(loc=0, scale=.5, size=len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                mean       std    median      5.0%     95.0%     n_eff     r_hat\n",
      "         m      2.46      0.19      2.46      2.15      2.76  10558.42      1.00\n",
      "       std      0.78      0.09      0.77      0.63      0.93   9656.62      1.00\n",
      "\n",
      "Number of divergences: 0\n"
     ]
    }
   ],
   "source": [
    "def model1_fn(x, t):\n",
    "    m = numpyro.sample('m', dist.Normal(0, 1e6))\n",
    "    std = numpyro.sample('std', dist.InverseGamma(2.5, 2.5 * 10))\n",
    "    \n",
    "    y = m * x\n",
    "    numpyro.sample('y', dist.Normal(y, std), obs=t)\n",
    "\n",
    "kernel = NUTS(model1_fn)\n",
    "model1 = MCMC(kernel, num_warmup, num_samples, num_chains=3)\n",
    "model1.run(rng_key, collect_warmup=False, x=x, t=t)\n",
    "samples1 = model1.get_samples()\n",
    "model1.print_summary() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                mean       std    median      5.0%     95.0%     n_eff     r_hat\n",
      "        m1      2.85      0.47      2.85      2.11      3.65   5454.76      1.00\n",
      "        m2     -0.64      0.69     -0.64     -1.77      0.47   5509.90      1.00\n",
      "       std      0.78      0.10      0.78      0.63      0.93   6562.06      1.00\n",
      "\n",
      "Number of divergences: 0\n"
     ]
    }
   ],
   "source": [
    "def model2_fn(x, t):\n",
    "    m1 = numpyro.sample('m1', dist.Normal(0, 1e6))\n",
    "    m2 = numpyro.sample('m2', dist.Normal(0, 1e6))\n",
    "    std = numpyro.sample('std', dist.InverseGamma(2.5, 2.5 * 10))\n",
    "    \n",
    "    y = m1 * x + m2 * x**3\n",
    "    numpyro.sample('y', dist.Normal(y, std), obs=t)\n",
    "\n",
    "kernel = NUTS(model2_fn)\n",
    "model2 = MCMC(kernel, num_warmup, num_samples, num_chains=3)\n",
    "model2.run(rng_key, collect_warmup=False, x=x, t=t)\n",
    "samples2 = model2.get_samples()\n",
    "model2.print_summary() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DIC\n",
    "\n",
    "The deviance is\n",
    "\n",
    "$$\n",
    "D(\\theta) = -2 \\log \\pi(Y \\mid \\theta),\n",
    "$$\n",
    "\n",
    "where $y$ are the data, $\\theta$ are the unknown parameters of the models and $\\pi(Y|\\theta)$ is the likelihood function. \n",
    "\n",
    "where \n",
    "\n",
    "$$\n",
    "\\pi(Y|\\theta) = \\prod_i^n \\pi(y_i|\\theta)\n",
    "$$\n",
    "\n",
    "and\n",
    "\n",
    "$$\n",
    "\\log \\pi(Y|\\theta) = \\sum_i^n \\log \\pi(y_i|\\theta)\n",
    "$$\n",
    "\n",
    "for $n$ data points.\n",
    "\n",
    "Thus the expected deviance, a measure of how well the model fits the data, is given by\n",
    "\n",
    "$$\n",
    "\\overline{D} = {\\rm E}_{\\theta}[D(\\theta)],\n",
    "$$\n",
    "\n",
    "while the effective number of parameters is\n",
    "\n",
    "$$\n",
    "p_D = \\overline{D} - D(\\theta^*),\n",
    "$$\n",
    "\n",
    "where $\\theta^*$ is point estimate of the posterior distribution, e.g., the posterior mean. Finally the DIC is given by\n",
    "\n",
    "$$\n",
    "{\\rm DIC} = p_D + \\overline{D}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dic(model_fn, samples, **kwargs):\n",
    "    pi_theta = numpyro.infer.log_likelihood(model_fn, samples, **kwargs)['y'].sum(axis=1)\n",
    "    D_bar = -2 * pi_theta.mean(axis=0)\n",
    "    theta_star = {k: v.mean(keepdims=True) for k, v in samples.items()}\n",
    "    pi_theta_star = numpyro.infer.log_likelihood(model_fn, theta_star, **kwargs)['y'].sum()\n",
    "    D_theta_star = -2 * pi_theta_star\n",
    "    print('expected deviance:', D_bar)\n",
    "    print('effective number of parameters:', D_bar - D_theta_star)\n",
    "    print('DIC:', D_bar - D_theta_star + D_bar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "expected deviance: 86.56448\n",
      "effective number of parameters: 1.0796051\n",
      "DIC: 87.64409\n"
     ]
    }
   ],
   "source": [
    "dic(model1_fn, samples1, x=x, t=t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "expected deviance: 86.833015\n",
      "effective number of parameters: 2.0190353\n",
      "DIC: 88.85205\n"
     ]
    }
   ],
   "source": [
    "dic(model2_fn, samples2, x=x, t=t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "models with smaller DIC should be preferred to models with larger DIC. Roughly speaking, differences of more than 10 might rule out the model with the higher DIC, differences between 5 and 10 are substantial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
